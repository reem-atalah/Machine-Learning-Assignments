{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVSWETW6WzkR"
      },
      "source": [
        "# Logistic Regression\n",
        "\n",
        "In this notebook, we will learn how to apply Logistic regression for predicting the cooling load requirements (Y2) of buildings as a function of building parameters (Xs).\n",
        "\n",
        "The attached dataset is taken from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Energy+efficiency).\n",
        "\n",
        "To run this code, you will need the following python packages:\n",
        "* numpy\n",
        "* pandas\n",
        "* openpyxl\n",
        "* scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RK5c9IxjWzkc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsJtrkVfWzkg"
      },
      "outputs": [],
      "source": [
        "# !pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Euq0GTUDWzkh"
      },
      "outputs": [],
      "source": [
        "# First, we load the dataset using pandas\n",
        "df = pd.read_excel(\"Energy_Efficiency.xlsx\", engine = 'openpyxl')\n",
        "# Remove any unnamed columns (might occur due to difference in pandas readers)\n",
        "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "# Remove any row with NaNs\n",
        "df = df.dropna(how='all')\n",
        "# Drop Y1 (as we only consider Y2 for classification)\n",
        "df = df.drop('Y1', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uAwbluAfWzki"
      },
      "outputs": [],
      "source": [
        "# next, we will split the dataframe into a training and testing splits with a 70% / 30% ratio\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_test = train_test_split(df, test_size=0.3, random_state=42) # Random is fixed for reproducability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "VZj4QWpzWzkj",
        "outputId": "38e03c6a-82f9-474d-b4c4-ac436f26640a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a2297c98-9985-489a-b6c0-61f8bcb97427\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>Y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>0.62</td>\n",
              "      <td>808.5</td>\n",
              "      <td>367.5</td>\n",
              "      <td>220.50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>15.77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>0.64</td>\n",
              "      <td>784.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>220.50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2</td>\n",
              "      <td>19.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>0.90</td>\n",
              "      <td>563.5</td>\n",
              "      <td>318.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.25</td>\n",
              "      <td>5</td>\n",
              "      <td>32.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>0.79</td>\n",
              "      <td>637.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>147.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.40</td>\n",
              "      <td>1</td>\n",
              "      <td>46.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.79</td>\n",
              "      <td>637.0</td>\n",
              "      <td>343.0</td>\n",
              "      <td>147.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>30.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>0.76</td>\n",
              "      <td>661.5</td>\n",
              "      <td>416.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>33.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0.86</td>\n",
              "      <td>588.0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>147.00</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2</td>\n",
              "      <td>27.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>0.71</td>\n",
              "      <td>710.5</td>\n",
              "      <td>269.5</td>\n",
              "      <td>220.50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>5</td>\n",
              "      <td>14.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>0.98</td>\n",
              "      <td>514.5</td>\n",
              "      <td>294.0</td>\n",
              "      <td>110.25</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.25</td>\n",
              "      <td>4</td>\n",
              "      <td>30.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.90</td>\n",
              "      <td>563.5</td>\n",
              "      <td>318.5</td>\n",
              "      <td>122.50</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>2</td>\n",
              "      <td>29.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>537 rows Ã— 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2297c98-9985-489a-b6c0-61f8bcb97427')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a2297c98-9985-489a-b6c0-61f8bcb97427 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a2297c98-9985-489a-b6c0-61f8bcb97427');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       X1     X2     X3      X4   X5  X6    X7  X8     Y2\n",
              "334  0.62  808.5  367.5  220.50  3.5   4  0.25   1  15.77\n",
              "139  0.64  784.0  343.0  220.50  3.5   5  0.10   2  19.30\n",
              "485  0.90  563.5  318.5  122.50  7.0   3  0.25   5  32.00\n",
              "547  0.79  637.0  343.0  147.00  7.0   5  0.40   1  46.94\n",
              "18   0.79  637.0  343.0  147.00  7.0   4  0.00   0  30.93\n",
              "..    ...    ...    ...     ...  ...  ..   ...  ..    ...\n",
              "71   0.76  661.5  416.5  122.50  7.0   5  0.10   1  33.67\n",
              "106  0.86  588.0  294.0  147.00  7.0   4  0.10   2  27.36\n",
              "270  0.71  710.5  269.5  220.50  3.5   4  0.10   5  14.26\n",
              "435  0.98  514.5  294.0  110.25  7.0   5  0.25   4  30.12\n",
              "102  0.90  563.5  318.5  122.50  7.0   4  0.10   2  29.36\n",
              "\n",
              "[537 rows x 9 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HqFuuEj3Wzkk",
        "outputId": "3129959e-019e-4982-f919-19d90cb3fa4e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-632ef9eb-932f-43df-bfaa-715239facea9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X1</th>\n",
              "      <th>X2</th>\n",
              "      <th>X3</th>\n",
              "      <th>X4</th>\n",
              "      <th>X5</th>\n",
              "      <th>X6</th>\n",
              "      <th>X7</th>\n",
              "      <th>X8</th>\n",
              "      <th>Y2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "      <td>537.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.760354</td>\n",
              "      <td>674.867784</td>\n",
              "      <td>318.636872</td>\n",
              "      <td>178.115456</td>\n",
              "      <td>5.201117</td>\n",
              "      <td>3.500931</td>\n",
              "      <td>0.235940</td>\n",
              "      <td>2.854749</td>\n",
              "      <td>24.287505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.104790</td>\n",
              "      <td>87.758133</td>\n",
              "      <td>43.619254</td>\n",
              "      <td>44.839207</td>\n",
              "      <td>1.750948</td>\n",
              "      <td>1.106502</td>\n",
              "      <td>0.134118</td>\n",
              "      <td>1.544532</td>\n",
              "      <td>9.505775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.620000</td>\n",
              "      <td>514.500000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>110.250000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.940000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.660000</td>\n",
              "      <td>612.500000</td>\n",
              "      <td>294.000000</td>\n",
              "      <td>147.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>15.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.740000</td>\n",
              "      <td>686.000000</td>\n",
              "      <td>318.500000</td>\n",
              "      <td>220.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>21.160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.820000</td>\n",
              "      <td>759.500000</td>\n",
              "      <td>343.000000</td>\n",
              "      <td>220.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>32.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.980000</td>\n",
              "      <td>808.500000</td>\n",
              "      <td>416.500000</td>\n",
              "      <td>220.500000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>48.030000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-632ef9eb-932f-43df-bfaa-715239facea9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-632ef9eb-932f-43df-bfaa-715239facea9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-632ef9eb-932f-43df-bfaa-715239facea9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "               X1          X2          X3          X4          X5          X6  \\\n",
              "count  537.000000  537.000000  537.000000  537.000000  537.000000  537.000000   \n",
              "mean     0.760354  674.867784  318.636872  178.115456    5.201117    3.500931   \n",
              "std      0.104790   87.758133   43.619254   44.839207    1.750948    1.106502   \n",
              "min      0.620000  514.500000  245.000000  110.250000    3.500000    2.000000   \n",
              "25%      0.660000  612.500000  294.000000  147.000000    3.500000    3.000000   \n",
              "50%      0.740000  686.000000  318.500000  220.500000    3.500000    3.000000   \n",
              "75%      0.820000  759.500000  343.000000  220.500000    7.000000    4.000000   \n",
              "max      0.980000  808.500000  416.500000  220.500000    7.000000    5.000000   \n",
              "\n",
              "               X7          X8          Y2  \n",
              "count  537.000000  537.000000  537.000000  \n",
              "mean     0.235940    2.854749   24.287505  \n",
              "std      0.134118    1.544532    9.505775  \n",
              "min      0.000000    0.000000   10.940000  \n",
              "25%      0.100000    2.000000   15.500000  \n",
              "50%      0.250000    3.000000   21.160000  \n",
              "75%      0.400000    4.000000   32.920000  \n",
              "max      0.400000    5.000000   48.030000  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL8W2LZ8Wzkl",
        "outputId": "beacc64f-ea50-4d63-911f-fd0b50eb5684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Median value of the target: 21.16\n",
            "Percentage of 'high load' samples: 49.906890130353815 %\n"
          ]
        }
      ],
      "source": [
        "# Now we will extract the models input and targets from both the training and testing dataframes\n",
        "def extract_Xy(df):\n",
        "    df_numpy = df.to_numpy()\n",
        "    return df_numpy[:, :-1], df_numpy[:, -1]\n",
        "\n",
        "X_train, y_train = extract_Xy(df_train)\n",
        "X_test, y_test = extract_Xy(df_test)\n",
        "\n",
        "y_median = np.median(y_train)\n",
        "print(\"Median value of the target:\", y_median)\n",
        "\n",
        "# Since we will treat this as a classification task, we will assume that\n",
        "# the load is \"high\" (y = True) if its compressive ratio is higher than the median\n",
        "# otherwise, it is assumed to be \"low\" (y = False)\n",
        "y_train = y_train > y_median\n",
        "y_test = y_test > y_median\n",
        "\n",
        "# Now ~50% of the samples should be considered \"high\" and the rest are considered \"low\"\n",
        "print(f\"Percentage of 'high load' samples: {y_train.mean() * 100} %\")\n",
        "\n",
        "# Also, lets standardize the data since it improves the training process\n",
        "X_mean = X_train.mean(axis=0)\n",
        "X_std = X_train.std(axis=0)\n",
        "X_train = (X_train - X_mean)/(1e-8 + X_std)\n",
        "X_test = (X_test - X_mean)/(1e-8 + X_std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGR7La-jWzkn"
      },
      "source": [
        "## Logistic Regression via Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gx9_xq01Wzkn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmBJ5WSxWzko",
        "outputId": "0fd9d6ee-ec23-4f8f-9219-395963e1bf90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 13.4 ms, sys: 0 ns, total: 13.4 ms\n",
            "Wall time: 22.8 ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# We use time to compute the training time of our model\n",
        "model = LogisticRegression(random_state=0, penalty=\"none\").fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWGNaf7oWzkp",
        "outputId": "7476fb01-d5ad-4c6d-aa14-1eb2fbab8d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accurracy: 98.32402234636871%\n",
            "Testing Accurracy: 96.53679653679653%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_train_predict = model.predict(X_train)\n",
        "print(f\"Training Accurracy: {accuracy_score(y_train, y_train_predict) * 100}%\")\n",
        "y_test_predict = model.predict(X_test)\n",
        "print(f\"Testing Accurracy: {accuracy_score(y_test, y_test_predict) * 100}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aae_NMFTWzkq"
      },
      "source": [
        "## Logistic Regression from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I_qMZBGGWzkr"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    #TODO: Implement sigmoid (hint: use np.exp)\n",
        "    # pass\n",
        "    return 1 / (1 + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pck5PQNqWzkr",
        "outputId": "187c49d4-c574-4c52-ef1a-931d8a824b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sigmoid(-1e2) = 3.7200759760208356e-44\n",
            "sigmoid(   0) = 0.5\n",
            "sigmoid(+1e2) = 1.0\n"
          ]
        }
      ],
      "source": [
        "# Sanity checks\n",
        "print(f\"{sigmoid(-1e2) = }\") # This should be almost equal 0\n",
        "print(f\"{sigmoid(   0) = }\") # This should be exactly 0.5\n",
        "print(f\"{sigmoid(+1e2) = }\") # This should be almost equal 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xe0aIXZsWzks"
      },
      "outputs": [],
      "source": [
        "def our_accuracy_score(true, predicted):\n",
        "    #TODO: Implement an accuracy metric so that is can be used instead of Sklearn's accuracy score\n",
        "    #Note: both true and predicted will be boolean numpy array\n",
        "    # pass\n",
        "    return np.sum(true == predicted) / len(true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnfeaVwjWzks",
        "outputId": "afae8ccc-ef1c-44bf-c259-dae71fa08f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "our_accuracy_score( np.array([True,  True]), np.array([True,  True]) ) = 1.0\n",
            "our_accuracy_score( np.array([True, False]), np.array([True,  True]) ) = 0.5\n",
            "our_accuracy_score( np.array([True, False]), np.array([True, False]) ) = 1.0\n",
            "our_accuracy_score( np.array([False, True]), np.array([True, False]) ) = 0.0\n"
          ]
        }
      ],
      "source": [
        "# Sanity checks\n",
        "print(f\"{our_accuracy_score( np.array([True,  True]), np.array([True,  True]) ) = }\") # Should be 1\n",
        "print(f\"{our_accuracy_score( np.array([True, False]), np.array([True,  True]) ) = }\") # Should be 0.5\n",
        "print(f\"{our_accuracy_score( np.array([True, False]), np.array([True, False]) ) = }\") # Should be 1\n",
        "print(f\"{our_accuracy_score( np.array([False, True]), np.array([True, False]) ) = }\") # Should be 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "q6okjDCzWzkt"
      },
      "outputs": [],
      "source": [
        "#IMPORTANT: You can only use numpy here. Do not use any premade algorithms (e.g. Scikit-Learn's Logistic Regression)\n",
        "class OurLogisticRegression:\n",
        "    def __init__(self, lr: int, epochs: int, probability_threshold: float = 0.5, random_state = None):\n",
        "        self.lr = lr # The learning rate\n",
        "        self.epochs = epochs # The number of training epochs\n",
        "        self.probability_threshold = probability_threshold # If the output of the sigmoid function is > probability_threshold, the prediction is considered to be positive (True)\n",
        "                                                           # otherwise, the prediction is considered to be negative (False)\n",
        "        self.random_state = random_state # The random state will be used set the random seed for the sake of reproducability\n",
        "    \n",
        "    def _prepare_input(self, X):\n",
        "        # Here, we add a new input with value 1 to each example. It will be multipled by the bias\n",
        "        ones = np.ones((X.shape[0], 1), dtype=X.dtype)\n",
        "        return np.concatenate((ones, X), axis=1)\n",
        "    \n",
        "    def _prepare_target(self, y):\n",
        "        # Here, we convert True to +1 and False to -1\n",
        "        #TODO (Optional): You can modify your function if you wish to used other values for the positive and negative classes\n",
        "        return np.where(y, 1, -1)\n",
        "\n",
        "    def _initialize(self, num_weights: int, stdev: float = 0.01):\n",
        "        # Here, we initialize the weights using a normally distributed random variable with a small standard deviation\n",
        "        self.w = np.random.randn(num_weights) * stdev\n",
        "\n",
        "    def _gradient(self, X, y):\n",
        "        #TODO: Compute and return the gradient of the weights (self.w) wrt to the loss given the X and y arrays\n",
        "        # pass\n",
        "        return np.dot(X.T, sigmoid(np.dot(X, self.w)) - y) / len(y)\n",
        "\n",
        "    def _update(self, X, y):\n",
        "        #TODO: Implement this function to apply a single iteration on the weights \"self.w\"\n",
        "        #Hint: use self._gradient\n",
        "        # pass\n",
        "        self.w -= self.lr * self._gradient(X, y)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state) # First, we set the seed\n",
        "        X = self._prepare_input(X) # Then we prepare the inputs\n",
        "        y = self._prepare_target(y) # and prepare the targets too\n",
        "        self._initialize(X.shape[1]) # and initialize the weights randomly\n",
        "        for _ in range(self.epochs): # Then we update the weights for a certain number of epochs\n",
        "            self._update(X, y)\n",
        "        return self # Return self to match the behavior of Scikit-Learn's LinearRegression fit()\n",
        "    \n",
        "    def predict(self, X):\n",
        "        X = self._prepare_input(X)\n",
        "        #TODO: Implement the rest of this function (Note: It should return a boolean array)\n",
        "        return sigmoid(np.dot(X, self.w)) > self.probability_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OfrcYYI_Wzku"
      },
      "outputs": [],
      "source": [
        "# We will use this function to tune the hyper parameters\n",
        "def validate(lr, epochs):\n",
        "    validation_size = None #TODO: Choose a size for the validation set as a ratio from the training data\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=validation_size, random_state=42)\n",
        "    # We will fit the model to only a subset of the training data and we will use the rest to evaluate the performance\n",
        "    our_model = OurLogisticRegression(lr=lr, epochs=epochs, random_state=0).fit(X_tr, y_tr)\n",
        "    # Then, we evaluate the peformance using the validation set\n",
        "    return our_accuracy_score(y_val, our_model.predict(X_val)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "499u1dilWzku",
        "outputId": "f5e87162-47c8-43e7-f03c-75aef97352b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In 1 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 2 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 3 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 4 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 5 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 6 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 7 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 8 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 9 epochs, the accuracy reaches 100.0% using lr=0.5\n",
            "In 10 epochs, the accuracy reaches 100.0% using lr=0.5\n"
          ]
        }
      ],
      "source": [
        "lr = None #TODO: Choose a learning rate to use while testing different values for the number of epochs\n",
        "epochs_values = [] #TODO: Choose a list of values for the number of epochs to test\n",
        "\n",
        "lr = 0.5\n",
        "epochs_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "for epochs in epochs_values:\n",
        "    accuracy = validate(lr, epochs)\n",
        "    print(f\"In {epochs} epochs, the accuracy reaches {accuracy * 100}% using lr={lr}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NObR8s5iWzkv",
        "outputId": "4577a7a3-956f-4b0f-c2aa-fbf52aaec142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using lr=0.01, the accuracy reaches 100.0% in 10 epochs\n",
            "Using lr=0.05, the accuracy reaches 100.0% in 10 epochs\n",
            "Using lr=0.1, the accuracy reaches 100.0% in 10 epochs\n",
            "Using lr=0.5, the accuracy reaches 100.0% in 10 epochs\n",
            "Using lr=1, the accuracy reaches 100.0% in 10 epochs\n",
            "Using lr=5, the accuracy reaches 100.0% in 10 epochs\n",
            "Using lr=10, the accuracy reaches 100.0% in 10 epochs\n"
          ]
        }
      ],
      "source": [
        "epochs = None #TODO: Choose the number of epochs to use while testing different values for the learning rate\n",
        "lr_values = [] #TODO: Choose a list of values for the learning rate to test\n",
        "\n",
        "epochs = 10\n",
        "lr_values = [0.01, 0.05, 0.1, 0.5, 1, 5, 10]\n",
        "for lr in lr_values:\n",
        "    accuracy = validate(lr, epochs)\n",
        "    print(f\"Using lr={lr}, the accuracy reaches {accuracy * 100}% in {epochs} epochs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHwuSJ-0Wzkv",
        "outputId": "09a6c0e8-02ee-4660-e52f-6c737a325cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2.01 ms, sys: 0 ns, total: 2.01 ms\n",
            "Wall time: 11.6 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# We use time to compute the training time of our model\n",
        "#TODO: Select an appropriate learning rate and number of epochs\n",
        "lr = 0.1\n",
        "epochs = 10\n",
        "our_model = OurLogisticRegression(lr=lr, epochs=epochs, random_state=0).fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmTwgpGjWzkv",
        "outputId": "8489e784-9176-43e3-d518-ed4e0707bb90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 98.32402234636871%\n",
            "Testing Accuracy: 96.53679653679653%\n"
          ]
        }
      ],
      "source": [
        "y_train_predict = our_model.predict(X_train)\n",
        "print(f\"Training Accuracy: {our_accuracy_score(y_train, y_train_predict) * 100}%\")\n",
        "y_test_predict = our_model.predict(X_test)\n",
        "print(f\"Testing Accuracy: {our_accuracy_score(y_test, y_test_predict) * 100}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E39f19dWzkw"
      },
      "outputs": [],
      "source": [
        "#TODO: Write your conclusion about your implementation's performance and training time\n",
        "# My implementation performance is similar to the sklearn implementation, similar accuracy \n",
        "# The training time of mine is less than the sklearn implementation due to less number of epoches"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "dd780a10ad03a506e232ec29f104692e8d999a77309c0fc915217df500c72051"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
